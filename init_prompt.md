# Cursor AI IDE ì—…ë¬´ ìë™í™” MCP ì„œë²„ ê°œë°œ í”„ë¡¬í”„íŠ¸

## í”„ë¡œì íŠ¸ ê°œìš”
ì—…ë¬´ ë‚´ìš©ì„ ìì—°ì–´ë¡œ ì…ë ¥í•˜ë©´ AIê°€ ë¶„ì„í•˜ì—¬ ì¼ì •, ì—…ë¬´ì¼ì§€, íšŒì˜ë¡ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , MCP ì„œë²„ë¥¼ í†µí•´ Calendar, Obsidianì— ìë™ ì •ë¦¬í•˜ë©°, Gantt Chartë¡œ ì‹œê°í™”í•˜ëŠ” í†µí•© ì—…ë¬´ ê´€ë¦¬ ì‹œìŠ¤í…œì„ ê°œë°œí•©ë‹ˆë‹¤.

## ê¸°ìˆ  ìŠ¤íƒ
- **ì–¸ì–´**: Python 3.11+
- **í”„ë ˆì„ì›Œí¬**: FastAPI (MCP ì„œë²„), Streamlit (ì›¹ UI)
- **MCP**: Model Context Protocol
- **NLP**: spaCy, transformers (ë¶„ë¥˜ ëª¨ë¸)
- **ë°ì´í„°ë² ì´ìŠ¤**: SQLite (ë¡œì»¬), PostgreSQL (í”„ë¡œë•ì…˜)
- **ì‹œê°í™”**: Plotly (Gantt Chart), Matplotlib
- **í†µí•©**: Obsidian API, Calendar API (Google Calendar)

## í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±

```
work-automation-mcp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ mcp_server/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ server.py
â”‚   â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ calendar_tool.py
â”‚   â”‚   â”‚   â”œâ”€â”€ obsidian_tool.py
â”‚   â”‚   â”‚   â””â”€â”€ gantt_tool.py
â”‚   â”‚   â””â”€â”€ handlers/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ text_analyzer.py
â”‚   â”‚       â””â”€â”€ content_classifier.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ database.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ nlp_processor.py
â”‚   â”‚   â””â”€â”€ date_parser.py
â”‚   â””â”€â”€ web_ui/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ app.py
â”‚       â””â”€â”€ components/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ input_form.py
â”‚           â””â”€â”€ dashboard.py
â”œâ”€â”€ tests/
â”œâ”€â”€ config/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ main.py
```

## ë‹¨ê³„ë³„ ê°œë°œ ê°€ì´ë“œ

### 1ë‹¨ê³„: ê¸°ë³¸ í”„ë¡œì íŠ¸ ì„¤ì •
```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install fastapi uvicorn pydantic sqlalchemy alembic
pip install spacy transformers torch
pip install streamlit plotly pandas
pip install python-multipart requests aiofiles
pip install mcp-server-python  # MCP ì„œë²„ ë¼ì´ë¸ŒëŸ¬ë¦¬
python -m spacy download ko_core_news_sm  # í•œêµ­ì–´ ëª¨ë¸
```

### 2ë‹¨ê³„: MCP ì„œë²„ í•µì‹¬ êµ¬í˜„

#### `src/mcp_server/server.py`
```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any
import asyncio
from .handlers.text_analyzer import TextAnalyzer
from .handlers.content_classifier import ContentClassifier
from .tools.calendar_tool import CalendarTool
from .tools.obsidian_tool import ObsidianTool
from .tools.gantt_tool import GanttTool

app = FastAPI(title="Work Automation MCP Server")

class WorkInput(BaseModel):
    text: str
    user_id: str
    timestamp: str

class ProcessedResult(BaseModel):
    category: str
    structured_data: Dict[str, Any]
    calendar_events: List[Dict]
    obsidian_notes: List[Dict]
    gantt_tasks: List[Dict]

# MCP ì„œë²„ ë„êµ¬ë“¤ ì´ˆê¸°í™”
text_analyzer = TextAnalyzer()
content_classifier = ContentClassifier()
calendar_tool = CalendarTool()
obsidian_tool = ObsidianTool()
gantt_tool = GanttTool()

@app.post("/process_work_input", response_model=ProcessedResult)
async def process_work_input(input_data: WorkInput):
    """
    ì—…ë¬´ ì…ë ¥ì„ ë¶„ì„í•˜ê³  ë¶„ë¥˜í•˜ì—¬ ê° ë„êµ¬ì— ì „ë‹¬
    """
    try:
        # 1. í…ìŠ¤íŠ¸ ë¶„ì„ ë° êµ¬ì¡°í™”
        analyzed_data = await text_analyzer.analyze(input_data.text)
        
        # 2. ì½˜í…ì¸  ë¶„ë¥˜ (ì¼ì •/ì—…ë¬´ì¼ì§€/íšŒì˜ë¡)
        category = await content_classifier.classify(analyzed_data)
        
        # 3. ê° ë„êµ¬ë³„ ë°ì´í„° ì²˜ë¦¬
        tasks = []
        
        if category in ['schedule', 'meeting']:
            tasks.append(calendar_tool.create_events(analyzed_data))
        
        if category in ['work_log', 'meeting']:
            tasks.append(obsidian_tool.create_notes(analyzed_data))
        
        if category in ['schedule', 'work_log']:
            tasks.append(gantt_tool.update_tasks(analyzed_data))
        
        # 4. ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return ProcessedResult(
            category=category,
            structured_data=analyzed_data,
            calendar_events=results[0] if len(results) > 0 else [],
            obsidian_notes=results[1] if len(results) > 1 else [],
            gantt_tasks=results[2] if len(results) > 2 else []
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    return {"status": "healthy", "server": "Work Automation MCP"}
```

### 3ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¶„ì„ê¸° êµ¬í˜„

#### `src/handlers/text_analyzer.py`
```python
import spacy
import re
from datetime import datetime, timedelta
from typing import Dict, List, Any
import asyncio

class TextAnalyzer:
    def __init__(self):
        self.nlp = spacy.load("ko_core_news_sm")
        self.date_patterns = [
            r'\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼',
            r'\d{1,2}ì›”\s*\d{1,2}ì¼',
            r'\d{1,2}/\d{1,2}',
            r'ì˜¤ëŠ˜|ë‚´ì¼|ëª¨ë ˆ|ë‹¤ìŒì£¼|ë‹¤ìŒë‹¬'
        ]
        
    async def analyze(self, text: str) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„° ë°˜í™˜
        """
        doc = self.nlp(text)
        
        # ë‚ ì§œ ë° ì‹œê°„ ì¶”ì¶œ
        dates = self._extract_dates(text)
        times = self._extract_times(text)
        
        # ì—”í‹°í‹° ì¶”ì¶œ
        entities = self._extract_entities(doc)
        
        # ì‘ì—… ë° ì•¡ì…˜ ì¶”ì¶œ
        tasks = self._extract_tasks(text)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(doc)
        
        return {
            "original_text": text,
            "dates": dates,
            "times": times,
            "entities": entities,
            "tasks": tasks,
            "keywords": keywords,
            "sentiment": self._analyze_sentiment(doc),
            "processed_at": datetime.now().isoformat()
        }
    
    def _extract_dates(self, text: str) -> List[str]:
        """ë‚ ì§œ íŒ¨í„´ ì¶”ì¶œ"""
        dates = []
        for pattern in self.date_patterns:
            matches = re.findall(pattern, text)
            dates.extend(matches)
        return dates
    
    def _extract_times(self, text: str) -> List[str]:
        """ì‹œê°„ íŒ¨í„´ ì¶”ì¶œ"""
        time_patterns = [
            r'\d{1,2}:\d{2}',
            r'\d{1,2}ì‹œ\s*\d{1,2}ë¶„',
            r'\d{1,2}ì‹œ',
            r'ì˜¤ì „|ì˜¤í›„'
        ]
        times = []
        for pattern in time_patterns:
            matches = re.findall(pattern, text)
            times.extend(matches)
        return times
    
    def _extract_entities(self, doc) -> Dict[str, List[str]]:
        """ëª…ëª…ëœ ì—”í‹°í‹° ì¶”ì¶œ"""
        entities = {
            "persons": [],
            "organizations": [],
            "locations": [],
            "misc": []
        }
        
        for ent in doc.ents:
            if ent.label_ == "PERSON":
                entities["persons"].append(ent.text)
            elif ent.label_ == "ORG":
                entities["organizations"].append(ent.text)
            elif ent.label_ == "LOC":
                entities["locations"].append(ent.text)
            else:
                entities["misc"].append(ent.text)
        
        return entities
    
    def _extract_tasks(self, text: str) -> List[str]:
        """ì‘ì—… í•­ëª© ì¶”ì¶œ"""
        task_patterns = [
            r'í•´ì•¼\s*í• \s*ì¼',
            r'ì™„ë£Œ\s*í•´ì•¼\s*í•¨',
            r'ì§„í–‰\s*ì¤‘',
            r'ê²€í† \s*í•„ìš”',
            r'ì‘ì—…\s*ì˜ˆì •'
        ]
        
        tasks = []
        for pattern in task_patterns:
            if re.search(pattern, text):
                # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ í•´ë‹¹ ì‘ì—… ì¶”ì¶œ
                sentences = text.split('.')
                for sentence in sentences:
                    if re.search(pattern, sentence):
                        tasks.append(sentence.strip())
        
        return tasks
    
    def _extract_keywords(self, doc) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        for token in doc:
            if (token.pos_ in ['NOUN', 'PROPN'] and 
                not token.is_stop and 
                not token.is_punct and 
                len(token.text) > 1):
                keywords.append(token.text)
        
        return list(set(keywords))
    
    def _analyze_sentiment(self, doc) -> str:
        """ê°ì • ë¶„ì„ (ê°„ë‹¨í•œ ë²„ì „)"""
        positive_words = ['ì¢‹ë‹¤', 'ì„±ê³µ', 'ì™„ë£Œ', 'ë‹¬ì„±', 'ë§Œì¡±']
        negative_words = ['ë¬¸ì œ', 'ì§€ì—°', 'ì‹¤íŒ¨', 'ì–´ë ¤ì›€', 'ë¶€ì¡±']
        
        text = doc.text
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        
        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "negative"
        else:
            return "neutral"
```

### 4ë‹¨ê³„: ì½˜í…ì¸  ë¶„ë¥˜ê¸° êµ¬í˜„

#### `src/handlers/content_classifier.py`
```python
import re
from typing import Dict, Any
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
import pickle
import os

class ContentClassifier:
    def __init__(self):
        self.model = None
        self.vectorizer = None
        self.categories = ['schedule', 'work_log', 'meeting']
        self._load_or_train_model()
    
    def _load_or_train_model(self):
        """ëª¨ë¸ ë¡œë“œ ë˜ëŠ” í›ˆë ¨"""
        model_path = "models/classifier.pkl"
        
        if os.path.exists(model_path):
            with open(model_path, 'rb') as f:
                self.model, self.vectorizer = pickle.load(f)
        else:
            self._train_initial_model()
    
    def _train_initial_model(self):
        """ì´ˆê¸° ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨"""
        # í›ˆë ¨ ë°ì´í„° (ì‹¤ì œ ì‚¬ìš©ì‹œ ë” ë§ì€ ë°ì´í„° í•„ìš”)
        training_data = [
            ("ë‚´ì¼ ì˜¤í›„ 3ì‹œì— íšŒì˜ê°€ ìˆìŠµë‹ˆë‹¤", "schedule"),
            ("í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™©ì„ ë³´ê³ ë“œë¦½ë‹ˆë‹¤", "work_log"),
            ("íšŒì˜ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤", "meeting"),
            ("ë‹¤ìŒì£¼ ì›”ìš”ì¼ê¹Œì§€ ì™„ë£Œ ì˜ˆì •ì…ë‹ˆë‹¤", "schedule"),
            ("ì˜¤ëŠ˜ ì‘ì—…í•œ ë‚´ìš©ì…ë‹ˆë‹¤", "work_log"),
            ("íšŒì˜ì—ì„œ ë…¼ì˜ëœ ì‚¬í•­ë“¤", "meeting")
        ]
        
        texts = [item[0] for item in training_data]
        labels = [item[1] for item in training_data]
        
        self.vectorizer = TfidfVectorizer(max_features=1000)
        X = self.vectorizer.fit_transform(texts)
        
        self.model = MultinomialNB()
        self.model.fit(X, labels)
        
        # ëª¨ë¸ ì €ì¥
        os.makedirs("models", exist_ok=True)
        with open("models/classifier.pkl", 'wb') as f:
            pickle.dump((self.model, self.vectorizer), f)
    
    async def classify(self, analyzed_data: Dict[str, Any]) -> str:
        """ë¶„ì„ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        text = analyzed_data["original_text"]
        
        # ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜ (ìš°ì„ ìˆœìœ„)
        if self._is_schedule(text, analyzed_data):
            return "schedule"
        elif self._is_meeting(text, analyzed_data):
            return "meeting"
        elif self._is_work_log(text, analyzed_data):
            return "work_log"
        
        # ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ë¶„ë¥˜
        if self.model and self.vectorizer:
            X = self.vectorizer.transform([text])
            prediction = self.model.predict(X)[0]
            return prediction
        
        return "work_log"  # ê¸°ë³¸ê°’
    
    def _is_schedule(self, text: str, data: Dict[str, Any]) -> bool:
        """ì¼ì • ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸"""
        schedule_keywords = ['íšŒì˜', 'ë¯¸íŒ…', 'ì¼ì •', 'ì•½ì†', 'ì˜ˆì •', 'ê³„íš']
        return any(keyword in text for keyword in schedule_keywords) and len(data['dates']) > 0
    
    def _is_meeting(self, text: str, data: Dict[str, Any]) -> bool:
        """íšŒì˜ë¡ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸"""
        meeting_keywords = ['íšŒì˜ë¡', 'íšŒì˜ ê²°ê³¼', 'ë…¼ì˜ì‚¬í•­', 'ê²°ì •ì‚¬í•­', 'ì•¡ì…˜ ì•„ì´í…œ']
        return any(keyword in text for keyword in meeting_keywords)
    
    def _is_work_log(self, text: str, data: Dict[str, Any]) -> bool:
        """ì—…ë¬´ì¼ì§€ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸"""
        work_keywords = ['ì‘ì—…', 'ì§„í–‰', 'ì™„ë£Œ', 'ìˆ˜í–‰', 'ì²˜ë¦¬', 'ê°œë°œ']
        return any(keyword in text for keyword in work_keywords)
```

### 5ë‹¨ê³„: Obsidian ë„êµ¬ êµ¬í˜„

#### `src/tools/obsidian_tool.py`
```python
import os
import json
from datetime import datetime
from typing import Dict, List, Any
import aiofiles
import asyncio

class ObsidianTool:
    def __init__(self, vault_path: str = "obsidian_vault"):
        self.vault_path = vault_path
        self.ensure_vault_structure()
    
    def ensure_vault_structure(self):
        """Obsidian ë³¼íŠ¸ êµ¬ì¡° ìƒì„±"""
        folders = [
            "Work_Logs",
            "Meetings",
            "Projects",
            "Templates"
        ]
        
        for folder in folders:
            folder_path = os.path.join(self.vault_path, folder)
            os.makedirs(folder_path, exist_ok=True)
    
    async def create_notes(self, analyzed_data: Dict[str, Any]) -> List[Dict]:
        """ë¶„ì„ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë…¸íŠ¸ ìƒì„±"""
        category = analyzed_data.get("category", "work_log")
        
        if category == "work_log":
            return await self._create_work_log(analyzed_data)
        elif category == "meeting":
            return await self._create_meeting_note(analyzed_data)
        elif category == "schedule":
            return await self._create_schedule_note(analyzed_data)
        
        return []
    
    async def _create_work_log(self, data: Dict[str, Any]) -> List[Dict]:
        """ì—…ë¬´ì¼ì§€ ë…¸íŠ¸ ìƒì„±"""
        date_str = datetime.now().strftime("%Y-%m-%d")
        filename = f"Work_Log_{date_str}.md"
        filepath = os.path.join(self.vault_path, "Work_Logs", filename)
        
        content = f"""# ì—…ë¬´ì¼ì§€ - {date_str}

## ì£¼ìš” ì‘ì—…
{data['original_text']}

## ì™„ë£Œ ì‚¬í•­
{self._format_tasks(data.get('tasks', []))}

## í‚¤ì›Œë“œ
{', '.join(data.get('keywords', []))}

## ê´€ë ¨ ì¸ë¬¼
{', '.join(data.get('entities', {}).get('persons', []))}

## ë©”ëª¨
- ì²˜ë¦¬ ì‹œê°„: {data['processed_at']}
- ê°ì •: {data.get('sentiment', 'neutral')}

---
íƒœê·¸: #ì—…ë¬´ì¼ì§€ #work #{date_str.replace('-', '/')}
"""
        
        await self._write_note(filepath, content)
        
        return [{
            "type": "work_log",
            "filename": filename,
            "path": filepath,
            "created_at": datetime.now().isoformat()
        }]
    
    async def _create_meeting_note(self, data: Dict[str, Any]) -> List[Dict]:
        """íšŒì˜ë¡ ë…¸íŠ¸ ìƒì„±"""
        date_str = datetime.now().strftime("%Y-%m-%d")
        filename = f"Meeting_{date_str}_{len(data.get('entities', {}).get('persons', []))}.md"
        filepath = os.path.join(self.vault_path, "Meetings", filename)
        
        content = f"""# íšŒì˜ë¡ - {date_str}

## ì°¸ì„ì
{self._format_participants(data.get('entities', {}).get('persons', []))}

## íšŒì˜ ë‚´ìš©
{data['original_text']}

## ì•¡ì…˜ ì•„ì´í…œ
{self._format_action_items(data.get('tasks', []))}

## ê²°ì •ì‚¬í•­
- ì¶”í›„ ì •ë¦¬ ì˜ˆì •

## ë‹¤ìŒ íšŒì˜
{self._format_next_meeting(data.get('dates', []))}

---
íƒœê·¸: #íšŒì˜ë¡ #meeting #{date_str.replace('-', '/')}
"""
        
        await self._write_note(filepath, content)
        
        return [{
            "type": "meeting",
            "filename": filename,
            "path": filepath,
            "created_at": datetime.now().isoformat()
        }]
    
    async def _create_schedule_note(self, data: Dict[str, Any]) -> List[Dict]:
        """ì¼ì • ë…¸íŠ¸ ìƒì„±"""
        date_str = datetime.now().strftime("%Y-%m-%d")
        filename = f"Schedule_{date_str}.md"
        filepath = os.path.join(self.vault_path, "Projects", filename)
        
        content = f"""# ì¼ì • - {date_str}

## ì˜ˆì •ëœ ì¼ì •
{self._format_schedule(data.get('dates', []), data.get('times', []))}

## ìƒì„¸ ë‚´ìš©
{data['original_text']}

## ê´€ë ¨ ì¸ë¬¼
{', '.join(data.get('entities', {}).get('persons', []))}

## ì¥ì†Œ
{', '.join(data.get('entities', {}).get('locations', []))}

---
íƒœê·¸: #ì¼ì • #schedule #{date_str.replace('-', '/')}
"""
        
        await self._write_note(filepath, content)
        
        return [{
            "type": "schedule",
            "filename": filename,
            "path": filepath,
            "created_at": datetime.now().isoformat()
        }]
    
    async def _write_note(self, filepath: str, content: str):
        """ë…¸íŠ¸ íŒŒì¼ ì‘ì„±"""
        async with aiofiles.open(filepath, 'w', encoding='utf-8') as f:
            await f.write(content)
    
    def _format_tasks(self, tasks: List[str]) -> str:
        """ì‘ì—… ëª©ë¡ í¬ë§·íŒ…"""
        if not tasks:
            return "- ì—†ìŒ"
        
        formatted = []
        for task in tasks:
            formatted.append(f"- [ ] {task}")
        
        return '\n'.join(formatted)
    
    def _format_participants(self, persons: List[str]) -> str:
        """ì°¸ì„ì ëª©ë¡ í¬ë§·íŒ…"""
        if not persons:
            return "- ì—†ìŒ"
        
        return '\n'.join([f"- {person}" for person in persons])
    
    def _format_action_items(self, tasks: List[str]) -> str:
        """ì•¡ì…˜ ì•„ì´í…œ í¬ë§·íŒ…"""
        return self._format_tasks(tasks)
    
    def _format_next_meeting(self, dates: List[str]) -> str:
        """ë‹¤ìŒ íšŒì˜ ì¼ì • í¬ë§·íŒ…"""
        if not dates:
            return "- ë¯¸ì •"
        
        return f"- {', '.join(dates)}"
    
    def _format_schedule(self, dates: List[str], times: List[str]) -> str:
        """ì¼ì • í¬ë§·íŒ…"""
        schedule_info = []
        
        if dates:
            schedule_info.append(f"ë‚ ì§œ: {', '.join(dates)}")
        
        if times:
            schedule_info.append(f"ì‹œê°„: {', '.join(times)}")
        
        return '\n'.join([f"- {info}" for info in schedule_info]) if schedule_info else "- ìƒì„¸ ì¼ì • ì—†ìŒ"
```

### 6ë‹¨ê³„: Streamlit ì›¹ UI êµ¬í˜„

#### `src/web_ui/app.py`
```python
import streamlit as st
import requests
import json
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import pandas as pd

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì—…ë¬´ ìë™í™” ì‹œìŠ¤í…œ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ë©”ì¸ UI
def main():
    st.title("ğŸ¤– AI ì—…ë¬´ ìë™í™” ì‹œìŠ¤í…œ")
    st.markdown("ì—…ë¬´ ë‚´ìš©ì„ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ì¼ì •, ì—…ë¬´ì¼ì§€, íšŒì˜ë¡ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ì •ë¦¬í•©ë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ì„¤ì •")
        server_url = st.text_input("MCP ì„œë²„ URL", "http://localhost:8000")
        user_id = st.text_input("ì‚¬ìš©ì ID", "user001")
        
        st.header("í†µê³„")
        show_stats()
    
    # ë©”ì¸ ì½˜í…ì¸ 
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.header("ğŸ“ ì—…ë¬´ ì…ë ¥")
        
        # í…ìŠ¤íŠ¸ ì…ë ¥
        work_input = st.text_area(
            "ì—…ë¬´ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:",
            height=200,
            placeholder="ì˜ˆ: ë‚´ì¼ ì˜¤í›„ 3ì‹œì— í”„ë¡œì íŠ¸ íšŒì˜ê°€ ìˆìŠµë‹ˆë‹¤. ê¹€íŒ€ì¥ë‹˜ê³¼ ì´ê°œë°œìë‹˜ì´ ì°¸ì„í•˜ê³ , ì§„í–‰ ìƒí™©ì„ ë³´ê³ í•  ì˜ˆì •ì…ë‹ˆë‹¤."
        )
        
        # ì²˜ë¦¬ ë²„íŠ¼
        if st.button("ğŸš€ ì²˜ë¦¬í•˜ê¸°", type="primary"):
            if work_input.strip():
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    result = process_work_input(work_input, user_id, server_url)
                    
                    if result:
                        st.success("ì²˜ë¦¬ ì™„ë£Œ!")
                        st.session_state.last_result = result
                    else:
                        st.error("ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ì—…ë¬´ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with col2:
        st.header("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼")
        
        if hasattr(st.session_state, 'last_result') and st.session_state.last_result:
            show_processing_result(st.session_state.last_result)
        else:
            st.info("ì—…ë¬´ ë‚´ìš©ì„ ì…ë ¥í•˜ê³  ì²˜ë¦¬í•˜ë©´ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
    
    # ê°„íŠ¸ ì°¨íŠ¸ ì„¹ì…˜
    st.header("ğŸ“ˆ Gantt Chart")
    show_gantt_chart()
    
    # ìµœê·¼ ì²˜ë¦¬ ë‚´ì—­
    st.header("ğŸ“‹ ìµœê·¼ ì²˜ë¦¬ ë‚´ì—­")
    show_recent_activities()

def process_work_input(text: str, user_id: str, server_url: str) -> dict:
    """ì—…ë¬´ ì…ë ¥ ì²˜ë¦¬"""
    try:
        response = requests.post(
            f"{server_url}/process_work_input",
            json={
                "text": text,
                "user_id": user_id,
                "timestamp": datetime.now().isoformat()
            },
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            st.error(f"ì„œë²„ ì˜¤ë¥˜: {response.status_code}")
            return None
            
    except requests.exceptions.RequestException as e:
        st.error(f"ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return None

def show_processing_result(result: dict):
    """ì²˜ë¦¬ ê²°ê³¼ í‘œì‹œ"""
    
    # ì¹´í…Œê³ ë¦¬ í‘œì‹œ
    category_map = {
        "schedule": "ğŸ“… ì¼ì •",
        "work_log": "ğŸ“ ì—…ë¬´ì¼ì§€",
        "meeting": "ğŸ¤ íšŒì˜ë¡"
    }
    
    category = result.get("category", "unknown")
    st.subheader(f"ë¶„ë¥˜: {category_map.get(category, category)}")
    
    # êµ¬ì¡°í™”ëœ ë°ì´í„° í‘œì‹œ
    with st.expander("ğŸ“Š ë¶„ì„ ê²°ê³¼"):
        structured_data = result.get("structured_data", {})
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ì¶”ì¶œëœ ë‚ ì§œ:**")
            dates = structured_data.get("dates", [])
            if dates:
                for date in dates:
                    st.write(f"- {date}")
            else:
                st.write("ì—†ìŒ")
            
            st.write("**ì¶”ì¶œëœ ì‹œê°„:**")
            times = structured_data.get("times", [])
            if times:
                for time in times:
                    st.write(f"- {time}")
            else:
                st.write("ì—†ìŒ")
        
        with col2:
            st.write("**ê´€ë ¨ ì¸ë¬¼:**")
            persons = structured_data.get("entities", {}).get("persons", [])
            if persons:
                for person in persons:
                    st.write(f"- {person}")
            else:
                st.write("ì—†ìŒ")
            
            st.write("**í‚¤ì›Œë“œ:**")
            keywords = structured_data.get("keywords", [])
            if keywords:
                st.write(", ".join(keywords[:10]))  # ìƒìœ„ 10ê°œë§Œ
            else:
                st.write("ì—†ìŒ")
    
    # ìƒì„±ëœ í•­ëª©ë“¤ í‘œì‹œ
    st.subheader("âœ… ìƒì„±ëœ í•­ëª©")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**ğŸ“… ìº˜ë¦°ë” ì´ë²¤íŠ¸**")
        calendar_events = result.get("calendar_events", [])
        st.write(f"{len(calendar_events)}ê°œ ìƒì„±ë¨")
    
    with col2:
        st.write("**ğŸ“ Obsidian ë…¸íŠ¸**")
        obsidian_notes = result.get("obsidian_notes", [])
        st.write(f"{len(obsidian_notes)}ê°œ ìƒì„±ë¨")
    
    with col3:
        st.write("**ğŸ“Š Gantt ì‘ì—…**")
        gantt_tasks = result.get("gantt_tasks", [])
        st.write(f"{len(gantt_tasks)}ê°œ ì—…ë°ì´íŠ¸ë¨")

def show_gantt_chart():
    """ê°„íŠ¸ ì°¨íŠ¸ í‘œì‹œ"""
    
    # ìƒ˜í”Œ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
    tasks_data = [
        {
            "Task": "í”„ë¡œì íŠ¸ ê¸°íš",
            "Start": "2024-01-01",
            "Finish": "2024-01-15",
            "Resource": "ê¸°íšíŒ€",
            "Status": "ì™„ë£Œ"
        },
        {
            "Task": "UI/UX ì„¤ê³„",
            "Start": "2024-01-10",
            "Finish": "2024-01-25",
            "Resource": "ë””ìì¸íŒ€",
            "Status": "ì§„í–‰ì¤‘"
        },
        {
            "Task": "ë°±ì—”ë“œ ê°œë°œ",
            "Start": "2024-01-20",
            "Finish": "2024-02-15",
            "Resource": "ê°œë°œíŒ€",
            "Status": "ì˜ˆì •"
        },
        {
            "Task": "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ",
            "Start": "2024-01-25",
            "Finish": "2024-02-20",
            "Resource": "ê°œë°œíŒ€",
            "Status": "ì˜ˆì •"
        },
        {
            "Task": "í…ŒìŠ¤íŠ¸ ë° ë°°í¬",
            "Start": "2024-02-15",
            "Finish": "2024-02-28",
            "Resource": "QAíŒ€",
            "Status": "ì˜ˆì •"
        }
    ]
    
    df = pd.DataFrame(tasks_data)
    df['Start'] = pd.to_datetime(df['Start'])
    df['Finish'] = pd.to_datetime(df['Finish'])
    
    # ìƒíƒœë³„ ìƒ‰ìƒ ë§¤í•‘
    color_map = {
        "ì™„ë£Œ": "green",
        "ì§„í–‰ì¤‘": "blue",
        "ì˜ˆì •": "orange",
        "ì§€ì—°": "red"
    }
    
    fig = go.Figure()
    
    for i, task in df.iterrows():
        fig.add_trace(go.Scatter(
            x=[task['Start'], task['Finish']],
            y=[i, i],
            mode='lines',
            line=dict(color=color_map.get(task['Status'], 'gray'), width=20),
            name=task['Task'],
            hovertemplate=f"<b>{task['Task']}</b><br>" +
                         f"ì‹œì‘: {task['Start'].strftime('%Y-%m-%d')}<br>" +
                         f"ì¢…ë£Œ: {task['Finish'].strftime('%Y-%m-%d')}<br>" +
                         f"ë‹´ë‹¹: {task['Resource']}<br>" +
                         f"ìƒíƒœ: {task['Status']}<extra></extra>"
        ))
    
    fig.update_layout(
        title="í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™©",
        xaxis_title="ë‚ ì§œ",
        yaxis_title="ì‘ì—…",
        yaxis=dict(
            tickmode='array',
            tickvals=list(range(len(df))),
            ticktext=df['Task'].tolist()
        ),
        showlegend=False,
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True)

def show_recent_activities():
    """ìµœê·¼ ì²˜ë¦¬ ë‚´ì—­ í‘œì‹œ"""
    
    # ìƒ˜í”Œ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
    activities = [
        {
            "ì‹œê°„": "2024-01-15 14:30",
            "ë¶„ë¥˜": "ğŸ“… ì¼ì •",
            "ë‚´ìš©": "í”„ë¡œì íŠ¸ íšŒì˜ ì¼ì • ë“±ë¡",
            "ìƒíƒœ": "ì™„ë£Œ"
        },
        {
            "ì‹œê°„": "2024-01-15 13:45",
            "ë¶„ë¥˜": "ğŸ“ ì—…ë¬´ì¼ì§€",
            "ë‚´ìš©": "API ê°œë°œ ì§„í–‰ ìƒí™© ê¸°ë¡",
            "ìƒíƒœ": "ì™„ë£Œ"
        },
        {
            "ì‹œê°„": "2024-01-15 11:20",
            "ë¶„ë¥˜": "ğŸ¤ íšŒì˜ë¡",
            "ë‚´ìš©": "ì£¼ê°„ íšŒì˜ ê²°ê³¼ ì •ë¦¬",
            "ìƒíƒœ": "ì™„ë£Œ"
        },
        {
            "ì‹œê°„": "2024-01-15 09:15",
            "ë¶„ë¥˜": "ğŸ“… ì¼ì •",
            "ë‚´ìš©": "í´ë¼ì´ì–¸íŠ¸ ë¯¸íŒ… ì˜ˆì•½",
            "ìƒíƒœ": "ì™„ë£Œ"
        }
    ]
    
    df = pd.DataFrame(activities)
    st.dataframe(df, use_container_width=True)

def show_stats():
    """í†µê³„ ì •ë³´ í‘œì‹œ"""
    
    # ìƒ˜í”Œ í†µê³„ ë°ì´í„°
    stats = {
        "ì˜¤ëŠ˜ ì²˜ë¦¬": 12,
        "ì´ë²ˆ ì£¼": 45,
        "ì´ë²ˆ ë‹¬": 156,
        "ì¼ì • ìƒì„±": 8,
        "ì—…ë¬´ì¼ì§€": 15,
        "íšŒì˜ë¡": 6
    }
    
    for key, value in stats.items():
        st.metric(key, value)

if __name__ == "__main__":
    main()
```

### 7ë‹¨ê³„: ìº˜ë¦°ë” ë„êµ¬ êµ¬í˜„

#### `src/tools/calendar_tool.py`
```python
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any
import re

class CalendarTool:
    def __init__(self):
        self.events = []  # ì‹¤ì œë¡œëŠ” Google Calendar API ë“± ì‚¬ìš©
    
    async def create_events(self, analyzed_data: Dict[str, Any]) -> List[Dict]:
        """ë¶„ì„ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìº˜ë¦°ë” ì´ë²¤íŠ¸ ìƒì„±"""
        events = []
        
        dates = analyzed_data.get('dates', [])
        times = analyzed_data.get('times', [])
        text = analyzed_data.get('original_text', '')
        
        if not dates:
            return events
        
        # ë‚ ì§œë³„ ì´ë²¤íŠ¸ ìƒì„±
        for date_str in dates:
            event = await self._create_single_event(date_str, times, text, analyzed_data)
            if event:
                events.append(event)
        
        return events
    
    async def _create_single_event(self, date_str: str, times: List[str], text: str, data: Dict[str, Any]) -> Dict:
        """ë‹¨ì¼ ì´ë²¤íŠ¸ ìƒì„±"""
        
        # ë‚ ì§œ íŒŒì‹±
        parsed_date = self._parse_date(date_str)
        if not parsed_date:
            return None
        
        # ì‹œê°„ íŒŒì‹±
        start_time, end_time = self._parse_time(times)
        
        # ì´ë²¤íŠ¸ ì œëª© ìƒì„±
        title = self._generate_title(text, data)
        
        # ì°¸ì„ì ì¶”ì¶œ
        attendees = data.get('entities', {}).get('persons', [])
        
        # ì¥ì†Œ ì¶”ì¶œ
        location = self._extract_location(data)
        
        event = {
            "id": f"event_{datetime.now().timestamp()}",
            "title": title,
            "start_date": parsed_date.isoformat(),
            "start_time": start_time,
            "end_time": end_time,
            "description": text,
            "attendees": attendees,
            "location": location,
            "created_at": datetime.now().isoformat(),
            "status": "confirmed"
        }
        
        # ì´ë²¤íŠ¸ ì €ì¥ (ì‹¤ì œë¡œëŠ” Google Calendar API ë“± ì‚¬ìš©)
        self.events.append(event)
        
        return event
    
    def _parse_date(self, date_str: str) -> datetime:
        """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹±"""
        
        # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€
        today = datetime.now()
        
        # ìƒëŒ€ì  ë‚ ì§œ ì²˜ë¦¬
        if 'ì˜¤ëŠ˜' in date_str:
            return today
        elif 'ë‚´ì¼' in date_str:
            return today + timedelta(days=1)
        elif 'ëª¨ë ˆ' in date_str:
            return today + timedelta(days=2)
        elif 'ë‹¤ìŒì£¼' in date_str:
            return today + timedelta(weeks=1)
        elif 'ë‹¤ìŒë‹¬' in date_str:
            return today + timedelta(days=30)
        
        # ì ˆëŒ€ì  ë‚ ì§œ ì²˜ë¦¬
        # 2024ë…„ 1ì›” 15ì¼ í˜•íƒœ
        year_month_day = re.search(r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼', date_str)
        if year_month_day:
            year, month, day = year_month_day.groups()
            return datetime(int(year), int(month), int(day))
        
        # 1ì›” 15ì¼ í˜•íƒœ
        month_day = re.search(r'(\d{1,2})ì›”\s*(\d{1,2})ì¼', date_str)
        if month_day:
            month, day = month_day.groups()
            return datetime(today.year, int(month), int(day))
        
        # 1/15 í˜•íƒœ
        slash_date = re.search(r'(\d{1,2})/(\d{1,2})', date_str)
        if slash_date:
            month, day = slash_date.groups()
            return datetime(today.year, int(month), int(day))
        
        return today
    
    def _parse_time(self, times: List[str]) -> tuple:
        """ì‹œê°„ ë¬¸ìì—´ íŒŒì‹±"""
        
        if not times:
            return "09:00", "10:00"  # ê¸°ë³¸ê°’
        
        start_time = "09:00"
        end_time = "10:00"
        
        for time_str in times:
            # 14:30 í˜•íƒœ
            hm_match = re.search(r'(\d{1,2}):(\d{2})', time_str)
            if hm_match:
                hour, minute = hm_match.groups()
                start_time = f"{hour.zfill(2)}:{minute}"
                # 1ì‹œê°„ í›„ë¥¼ ì¢…ë£Œ ì‹œê°„ìœ¼ë¡œ ì„¤ì •
                end_hour = (int(hour) + 1) % 24
                end_time = f"{str(end_hour).zfill(2)}:{minute}"
                break
            
            # 14ì‹œ 30ë¶„ í˜•íƒœ
            korean_time = re.search(r'(\d{1,2})ì‹œ\s*(\d{1,2})?ë¶„?', time_str)
            if korean_time:
                hour = korean_time.group(1)
                minute = korean_time.group(2) or "00"
                start_time = f"{hour.zfill(2)}:{minute.zfill(2)}"
                end_hour = (int(hour) + 1) % 24
                end_time = f"{str(end_hour).zfill(2)}:{minute.zfill(2)}"
                break
        
        return start_time, end_time
    
    def _generate_title(self, text: str, data: Dict[str, Any]) -> str:
        """ì´ë²¤íŠ¸ ì œëª© ìƒì„±"""
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì œëª© ìƒì„±
        keywords = data.get('keywords', [])
        
        if 'íšŒì˜' in text:
            if keywords:
                return f"{keywords[0]} íšŒì˜"
            return "íšŒì˜"
        elif 'ë¯¸íŒ…' in text:
            if keywords:
                return f"{keywords[0]} ë¯¸íŒ…"
            return "ë¯¸íŒ…"
        elif 'ì¼ì •' in text:
            if keywords:
                return f"{keywords[0]} ì¼ì •"
            return "ì¼ì •"
        
        # í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ í‚¤ì›Œë“œë¥¼ ì œëª©ìœ¼ë¡œ
        if keywords:
            return keywords[0]
        
        # ê¸°ë³¸ ì œëª©
        return "ì¼ì •"
    
    def _extract_location(self, data: Dict[str, Any]) -> str:
        """ì¥ì†Œ ì •ë³´ ì¶”ì¶œ"""
        locations = data.get('entities', {}).get('locations', [])
        
        if locations:
            return locations[0]
        
        # í…ìŠ¤íŠ¸ì—ì„œ ì¥ì†Œ íŒ¨í„´ ì°¾ê¸°
        text = data.get('original_text', '')
        location_patterns = [
            r'(\w+ì‹¤)',
            r'(\w+í˜¸)',
            r'(\w+ì¸µ)',
            r'(\w+ì„¼í„°)',
            r'(\w+ë¹Œë”©)'
        ]
        
        for pattern in location_patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(1)
        
        return "ë¯¸ì •"

### 8ë‹¨ê³„: Gantt ì°¨íŠ¸ ë„êµ¬ êµ¬í˜„

#### `src/tools/gantt_tool.py`
```python
import json
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Any
import re

class GanttTool:
    def __init__(self, db_path: str = "gantt_data.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS tasks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                description TEXT,
                start_date TEXT,
                end_date TEXT,
                progress INTEGER DEFAULT 0,
                status TEXT DEFAULT 'planned',
                assignee TEXT,
                project TEXT,
                created_at TEXT,
                updated_at TEXT
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS dependencies (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                task_id INTEGER,
                depends_on_id INTEGER,
                FOREIGN KEY (task_id) REFERENCES tasks (id),
                FOREIGN KEY (depends_on_id) REFERENCES tasks (id)
            )
        ''')
        
        conn.commit()
        conn.close()
    
    async def update_tasks(self, analyzed_data: Dict[str, Any]) -> List[Dict]:
        """ë¶„ì„ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Gantt ì°¨íŠ¸ ì‘ì—… ì—…ë°ì´íŠ¸"""
        
        tasks = []
        text = analyzed_data.get('original_text', '')
        
        # ì‘ì—… ì¶”ì¶œ
        extracted_tasks = self._extract_tasks_from_text(text, analyzed_data)
        
        for task_data in extracted_tasks:
            task = await self._create_or_update_task(task_data)
            if task:
                tasks.append(task)
        
        return tasks
    
    def _extract_tasks_from_text(self, text: str, data: Dict[str, Any]) -> List[Dict]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì‘ì—… ì •ë³´ ì¶”ì¶œ"""
        
        tasks = []
        
        # ì‘ì—… ê´€ë ¨ íŒ¨í„´
        task_patterns = [
            r'(\w+)\s*ì‘ì—…',
            r'(\w+)\s*ê°œë°œ',
            r'(\w+)\s*êµ¬í˜„',
            r'(\w+)\s*ì„¤ê³„',
            r'(\w+)\s*í…ŒìŠ¤íŠ¸',
            r'(\w+)\s*ë°°í¬'
        ]
        
        # ì§„í–‰ ìƒíƒœ íŒ¨í„´
        progress_patterns = {
            r'ì‹œì‘|ì°©ìˆ˜': 10,
            r'ì§„í–‰\s*ì¤‘': 50,
            r'ì™„ë£Œ|ì¢…ë£Œ': 100,
            r'ê²€í† \s*ì¤‘': 80,
            r'í…ŒìŠ¤íŠ¸\s*ì¤‘': 90
        }
        
        # ë‚ ì§œ ì •ë³´
        dates = data.get('dates', [])
        assignees = data.get('entities', {}).get('persons', [])
        
        # ì‘ì—… ì¶”ì¶œ
        for pattern in task_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                
                # ì§„í–‰ë¥  ê³„ì‚°
                progress = 0
                for prog_pattern, prog_value in progress_patterns.items():
                    if re.search(prog_pattern, text):
                        progress = prog_value
                        break
                
                # ìƒíƒœ ê²°ì •
                if progress == 0:
                    status = 'planned'
                elif progress == 100:
                    status = 'completed'
                else:
                    status = 'in_progress'
                
                task = {
                    'title': f"{match} ì‘ì—…",
                    'description': text[:100] + "..." if len(text) > 100 else text,
                    'start_date': self._parse_start_date(dates),
                    'end_date': self._parse_end_date(dates),
                    'progress': progress,
                    'status': status,
                    'assignee': assignees[0] if assignees else 'ë¯¸ì •',
                    'project': self._extract_project_name(text, data)
                }
                
                tasks.append(task)
        
        return tasks
    
    async def _create_or_update_task(self, task_data: Dict[str, Any]) -> Dict:
        """ì‘ì—… ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ê¸°ì¡´ ì‘ì—… í™•ì¸
        cursor.execute('''
            SELECT id FROM tasks 
            WHERE title = ? AND project = ?
        ''', (task_data['title'], task_data['project']))
        
        existing_task = cursor.fetchone()
        
        if existing_task:
            # ê¸°ì¡´ ì‘ì—… ì—…ë°ì´íŠ¸
            cursor.execute('''
                UPDATE tasks SET
                    description = ?,
                    start_date = ?,
                    end_date = ?,
                    progress = ?,
                    status = ?,
                    assignee = ?,
                    updated_at = ?
                WHERE id = ?
            ''', (
                task_data['description'],
                task_data['start_date'],
                task_data['end_date'],
                task_data['progress'],
                task_data['status'],
                task_data['assignee'],
                datetime.now().isoformat(),
                existing_task[0]
            ))
            
            task_id = existing_task[0]
        else:
            # ìƒˆ ì‘ì—… ìƒì„±
            cursor.execute('''
                INSERT INTO tasks (
                    title, description, start_date, end_date, 
                    progress, status, assignee, project, 
                    created_at, updated_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                task_data['title'],
                task_data['description'],
                task_data['start_date'],
                task_data['end_date'],
                task_data['progress'],
                task_data['status'],
                task_data['assignee'],
                task_data['project'],
                datetime.now().isoformat(),
                datetime.now().isoformat()
            ))
            
            task_id = cursor.lastrowid
        
        conn.commit()
        
        # ìƒì„±/ì—…ë°ì´íŠ¸ëœ ì‘ì—… ì •ë³´ ë°˜í™˜
        cursor.execute('SELECT * FROM tasks WHERE id = ?', (task_id,))
        task_row = cursor.fetchone()
        
        conn.close()
        
        if task_row:
            return {
                'id': task_row[0],
                'title': task_row[1],
                'description': task_row[2],
                'start_date': task_row[3],
                'end_date': task_row[4],
                'progress': task_row[5],
                'status': task_row[6],
                'assignee': task_row[7],
                'project': task_row[8],
                'created_at': task_row[9],
                'updated_at': task_row[10]
            }
        
        return None
    
    def _parse_start_date(self, dates: List[str]) -> str:
        """ì‹œì‘ ë‚ ì§œ íŒŒì‹±"""
        if dates:
            # ì²« ë²ˆì§¸ ë‚ ì§œë¥¼ ì‹œì‘ ë‚ ì§œë¡œ ì‚¬ìš©
            return self._convert_date_to_iso(dates[0])
        
        # ê¸°ë³¸ê°’: ì˜¤ëŠ˜
        return datetime.now().isoformat()
    
    def _parse_end_date(self, dates: List[str]) -> str:
        """ì¢…ë£Œ ë‚ ì§œ íŒŒì‹±"""
        if len(dates) > 1:
            # ë‘ ë²ˆì§¸ ë‚ ì§œë¥¼ ì¢…ë£Œ ë‚ ì§œë¡œ ì‚¬ìš©
            return self._convert_date_to_iso(dates[1])
        elif len(dates) == 1:
            # í•˜ë‚˜ì˜ ë‚ ì§œë§Œ ìˆìœ¼ë©´ 1ì£¼ì¼ í›„ë¥¼ ì¢…ë£Œ ë‚ ì§œë¡œ ì„¤ì •
            start_date = self._convert_date_to_iso(dates[0])
            start_dt = datetime.fromisoformat(start_date)
            end_dt = start_dt + timedelta(weeks=1)
            return end_dt.isoformat()
        
        # ê¸°ë³¸ê°’: 1ì£¼ì¼ í›„
        return (datetime.now() + timedelta(weeks=1)).isoformat()
    
    def _convert_date_to_iso(self, date_str: str) -> str:
        """ë‚ ì§œ ë¬¸ìì—´ì„ ISO í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        # ë‚ ì§œ íŒŒì‹± ë¡œì§ (CalendarToolê³¼ ìœ ì‚¬)
        today = datetime.now()
        
        if 'ì˜¤ëŠ˜' in date_str:
            return today.isoformat()
        elif 'ë‚´ì¼' in date_str:
            return (today + timedelta(days=1)).isoformat()
        elif 'ëª¨ë ˆ' in date_str:
            return (today + timedelta(days=2)).isoformat()
        
        # ê¸°ë³¸ê°’
        return today.isoformat()
    
    def _extract_project_name(self, text: str, data: Dict[str, Any]) -> str:
        """í”„ë¡œì íŠ¸ ì´ë¦„ ì¶”ì¶œ"""
        
        keywords = data.get('keywords', [])
        
        # í”„ë¡œì íŠ¸ ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°
        project_keywords = ['í”„ë¡œì íŠ¸', 'ì‹œìŠ¤í…œ', 'í”Œë«í¼', 'ì„œë¹„ìŠ¤', 'ì•±']
        
        for keyword in keywords:
            if any(proj_key in keyword for proj_key in project_keywords):
                return keyword
        
        # ì²« ë²ˆì§¸ í‚¤ì›Œë“œë¥¼ í”„ë¡œì íŠ¸ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©
        if keywords:
            return keywords[0]
        
        return "ê¸°ë³¸ í”„ë¡œì íŠ¸"
    
    def get_all_tasks(self) -> List[Dict]:
        """ëª¨ë“  ì‘ì—… ì¡°íšŒ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT * FROM tasks ORDER BY start_date')
        tasks = cursor.fetchall()
        
        conn.close()
        
        return [
            {
                'id': task[0],
                'title': task[1],
                'description': task[2],
                'start_date': task[3],
                'end_date': task[4],
                'progress': task[5],
                'status': task[6],
                'assignee': task[7],
                'project': task[8],
                'created_at': task[9],
                'updated_at': task[10]
            }
            for task in tasks
        ]

### 9ë‹¨ê³„: ë©”ì¸ ì‹¤í–‰ íŒŒì¼

#### `main.py`
```python
import uvicorn
import asyncio
from src.mcp_server.server import app
from src.models.database import init_database

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    await init_database()
    
    # ì„œë²„ ì‹¤í–‰
    config = uvicorn.Config(
        app=app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
    
    server = uvicorn.Server(config)
    await server.serve()

if __name__ == "__main__":
    asyncio.run(main())
```

#### `requirements.txt`
```
fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.5.0
sqlalchemy==2.0.23
alembic==1.13.1
spacy==3.7.2
transformers==4.35.2
torch==2.1.1
streamlit==1.28.1
plotly==5.17.0
pandas==2.1.3
python-multipart==0.0.6
requests==2.31.0
aiofiles==23.2.1
scikit-learn==1.3.2
python-dateutil==2.8.2
```

### 10ë‹¨ê³„: ì‹¤í–‰ ëª…ë ¹ì–´

#### ê°œë°œ í™˜ê²½ ì„¤ì •
```bash
# 1. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir work-automation-mcp
cd work-automation-mcp

# 2. ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 4. í•œêµ­ì–´ spaCy ëª¨ë¸ ì„¤ì¹˜
python -m spacy download ko_core_news_sm

# 5. MCP ì„œë²„ ì‹¤í–‰
python main.py

# 6. ì›¹ UI ì‹¤í–‰ (ìƒˆ í„°ë¯¸ë„)
streamlit run src/web_ui/app.py
```

### ê°œë°œ ìš°ì„ ìˆœìœ„ ë° ë‹¨ê³„

1. **1ë‹¨ê³„**: ê¸°ë³¸ MCP ì„œë²„ êµ¬ì¶• ë° í…ìŠ¤íŠ¸ ë¶„ì„ê¸° ê°œë°œ
2. **2ë‹¨ê³„**: ì½˜í…ì¸  ë¶„ë¥˜ê¸° êµ¬í˜„ ë° í›ˆë ¨
3. **3ë‹¨ê³„**: Obsidian ë„êµ¬ êµ¬í˜„ ë° ë…¸íŠ¸ ìë™ ìƒì„±
4. **4ë‹¨ê³„**: ìº˜ë¦°ë” ë„êµ¬ êµ¬í˜„ ë° Google Calendar ì—°ë™
5. **5ë‹¨ê³„**: Gantt ì°¨íŠ¸ ë„êµ¬ êµ¬í˜„ ë° ì‹œê°í™”
6. **6ë‹¨ê³„**: Streamlit ì›¹ UI ê°œë°œ ë° í†µí•©
7. **7ë‹¨ê³„**: ì„±ëŠ¥ ìµœì í™” ë° ì˜¤ë¥˜ ì²˜ë¦¬
8. **8ë‹¨ê³„**: í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„± ë° ë°°í¬ ì¤€ë¹„

### ì¶”ê°€ ê¸°ëŠ¥ í™•ì¥ ì•„ì´ë””ì–´

- **ìŒì„± ì…ë ¥**: ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬
- **ì´ë©”ì¼ í†µí•©**: ì´ë©”ì¼ ë‚´ìš© ìë™ ë¶„ì„ ë° ë¶„ë¥˜
- **Slack/Teams ì—°ë™**: ë©”ì‹œì§€ ë‚´ìš© ìë™ ì²˜ë¦¬
- **AI ì–´ì‹œìŠ¤í„´íŠ¸**: ì—…ë¬´ ê´€ë ¨ ì§ˆë¬¸ ë‹µë³€ ê¸°ëŠ¥
- **ë³´ê³ ì„œ ìë™ ìƒì„±**: ì£¼ê°„/ì›”ê°„ ì—…ë¬´ ë³´ê³ ì„œ ìë™ ì‘ì„±
- **ì•Œë¦¼ ì‹œìŠ¤í…œ**: ì¼ì • ë° ë§ˆê°ì¼ ì•Œë¦¼ ê¸°ëŠ¥

ì´ í”„ë¡¬í”„íŠ¸ë¥¼ Cursor AI IDEì— ì…ë ¥í•˜ë©´ ë‹¨ê³„ë³„ë¡œ ê°œë°œì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.